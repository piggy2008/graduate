\chapter{中文摘要}
\renewcommand{\leftmark}{中文摘要}
显著性目标检测是旨在检测并确定自然场景中最能吸引人类注意力的目标区域。相比于高层的计算机视觉算法，如目标检测、目标跟踪、图像检测，显著性目标检测属于底层的图像处理方法，可以利用其结果来提高其他图像算法的速度和精度。由于显著性算法的输入数据不同，产生了图像显著性目标检测和视频显著性目标检测。相对比图像显著性，视频显著性需要同时考虑单帧图像中的空间特性和视频序列中的时间特性，其计算更复杂，场景也更多样，挑战性也更高。因此，本文的研究任务即为视频场景下的显著性目标检测。最近几年，由于深度学习在各个计算机视觉任务上的突破，基于深度学习的视频显著性目标检测的方法也成为一个热点研究问题。然而，现阶段基于深度学习的视频显著性检测仍存在几个亟待解决的难点。1）训练数据不足。在使用深度网络来解决计算机视觉任务时，需要大量标记后的图像样本来训练深度网络。在视频显著性检测中，需要对连续视频帧进行像素级别的标定，而且这样的标定需要消耗大量的人工，因此目前可用于深度训练的视频显著性目标检测训练集较少。2）传统的深度网络无法适用于视频序列。深度网络已经在图像显著性检测中获得了成功，也大大地提高图像显著性检测的准确率和效率。但是，相比于图像数据，视频序列更为复杂，不仅需要考虑单站中的空间信息，还需要考虑序列之间的帧间信息。所以，传统的深度结构不足完成复杂场景下的视频显著性检测。3）运动深度特征的鲁棒性有待提升。现有方法中，对于深度运动特征提取还不是很充分，当前的网络结构没有很好的完成运动目标的特征提取。4）特征融合方式也存在提升空间。在分别完成静态特征和运动特征的提取后，需要一个合理的方法完成特征融合。目前在这一方法的研究仍有不足。本文针对上述四个问题展开研究，依次解决上述问题，从而逐渐地提高视频显著性目标检测的准确率。本文主要的研究内容包括以下三个方面:

1）基于弱监督时空级联网络的视频显著性目标检测方法。该方法主要解决训练数据不足和传统静态网络不适用的问题。首先，针对训练数据不足，提出使用弱监督的学习方法，在网络训练的过程中产生弱标签，利用这些弱标签完成网络的训练。其次，针对传统网络不适用视频数据的问题，提出了一个新型的级联深度网络。在第一个深度子网中生成静态特征图，再利用一个动态先验图的引导，利用级联的第二个深度子网生成最终的显著图。该方法不需要另外增加像素级标记，而且由于有动态先验的引导，可以很好地完成深度网络的训练，生成准确率较高的显著图。

2）注意力时空特征融合的显著性检测。在这一研究内容中，提出一个并行的双流子网深度模型，分别用来提取静态特征和动态特征。在整个模型的后端，本文提出一个基于注意力机制的模块来完成时空特征的融合，最终生成高准确率的特征图。相比上一个研究方法，该方法则提出了更为合理的深度模型，并且在网络中进一步挖掘高鲁棒性的运动特征，并且找到了一个更为合理的时空特征融合机制，即注意力时空特征融合，从而使得显著图的效果更好。

3）待定
%\blindtext 